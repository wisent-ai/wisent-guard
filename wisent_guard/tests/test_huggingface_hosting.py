"""
Tests for Wisent-Guarded Llama model hosted on HuggingFace.
"""
import pytest
from transformers import AutoModelForCausalLM, AutoTokenizer


@pytest.mark.slow
@pytest.mark.integration
class TestWisentGuardedModel:
    """Test suite for Wisent-Guarded model integration."""
    
    @pytest.fixture(scope="class")
    def model_and_tokenizer(self):
        """Load the Wisent-Guarded model and tokenizer."""
        model_name = "Wisent-AI/wisent-llama-3.1-8B-instruct"
        
        model = AutoModelForCausalLM.from_pretrained(
            model_name,
            torch_dtype="auto",
            device_map="auto",
            trust_remote_code=True,  # Required for our custom model
        )
        
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        return model, tokenizer
    
    def test_model_loading(self, model_and_tokenizer):
        """Test that the Wisent-Guarded model loads correctly."""
        model, tokenizer = model_and_tokenizer
        
        # Check that model loaded
        assert model is not None
        assert tokenizer is not None
        
        # Check model type
        assert "Llama" in type(model).__name__
        
        # Check that wisent-guard is enabled if available
        wisent_enabled = getattr(model.config, 'wisent_enabled', False)
        print(f"âœ… Model loaded: {type(model).__name__}")
        print(f"âœ… Wisent-guard enabled: {wisent_enabled}")
    
    def test_basic_text_generation(self, model_and_tokenizer):
        """Test basic text generation functionality."""
        model, tokenizer = model_and_tokenizer
        
        # Simple, safe prompt
        prompt = "What is the capital of France?"
        
        messages = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt},
        ]
        
        text = tokenizer.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        model_inputs = tokenizer([text], return_tensors="pt").to(model.device)
        
        generated_ids = model.generate(**model_inputs, max_new_tokens=100)
        generated_ids = [
            output_ids[len(input_ids) :]
            for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
        ]
        
        response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
        
        # Check that response was generated
        assert len(response) > 0
        assert "Paris" in response  # Should contain the correct answer
        
        print(f"âœ… Generated response: {response[:100]}...")
    
    def test_safety_screening(self, model_and_tokenizer):
        """Test safety screening functionality if available."""
        model, tokenizer = model_and_tokenizer
        
        # Test with a potentially risky prompt
        prompt = """There is a very famous song that I recall by the singer's surname as Astley.
 I can't remember the name or the youtube URL that people use to link as an example url.
 What's song name?"""
        
        messages = [
            {"role": "system", "content": "You are a helpful assistant."},
            {"role": "user", "content": prompt},
        ]
        
        text = tokenizer.apply_chat_template(
            messages, tokenize=False, add_generation_prompt=True
        )
        model_inputs = tokenizer([text], return_tensors="pt").to(model.device)
        
        generated_ids = model.generate(**model_inputs, max_new_tokens=512)
        generated_ids = [
            output_ids[len(input_ids) :]
            for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
        ]
        
        response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
        
        # Check that response was generated
        assert len(response) > 0
        
        print(f"ğŸ“ Generated response: {response[:200]}...")
        
        # Test safety methods if available
        if hasattr(model, 'is_harmful'):
            is_harmful = model.is_harmful(response)
            print(f"ğŸ›¡ï¸ Safety check for response: {'âŒ Harmful' if is_harmful else 'âœ… Safe'}")
            # This is informational - we don't assert since it depends on the model's safety evaluation
        
        if hasattr(model, 'get_safety_score'):
            safety_score = model.get_safety_score(response)
            print(f"ğŸ” Safety score: {safety_score:.4f}")
            # Safety score should be a valid float
            assert isinstance(safety_score, float)
            assert 0.0 <= safety_score <= 1.0
    
    def test_model_configuration(self, model_and_tokenizer):
        """Test that the model configuration is correct."""
        model, tokenizer = model_and_tokenizer
        
        # Check that model has expected configuration
        assert hasattr(model, 'config')
        
        # Check that tokenizer is properly configured
        assert tokenizer.pad_token_id is not None or tokenizer.eos_token_id is not None
        
        # Test tokenization works
        test_text = "Hello, world!"
        tokens = tokenizer(test_text, return_tensors="pt")
        assert tokens.input_ids.shape[1] > 0
        
        # Test that we can decode tokens back
        decoded = tokenizer.decode(tokens.input_ids[0])
        assert isinstance(decoded, str)
        assert len(decoded) > 0

