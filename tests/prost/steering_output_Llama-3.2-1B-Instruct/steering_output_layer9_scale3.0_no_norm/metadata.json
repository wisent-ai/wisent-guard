{
  "timestamp": "2025-10-02T21:43:31.312124+02:00",
  "model_name": "meta-llama/Llama-3.2-1B-Instruct",
  "layers_used": [
    "9"
  ],
  "method": "caa",
  "method_kwargs": {},
  "activation_aggregation_strategy": "continuation_token",
  "return_full_sequence": false,
  "normalize_layers": false,
  "num_pairs": 24,
  "hidden_size": 2048
}